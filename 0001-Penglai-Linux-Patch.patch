From 09fa8c0e0fb5e8fddffe75b0176d30c681e05c57 Mon Sep 17 00:00:00 2001
From: fengeh <2748250768@qq.com>
Date: Mon, 1 Mar 2021 14:09:18 +0800
Subject: [PATCH] Penglai Linux Patch

---
 arch/riscv/Kconfig                  |   8 +
 arch/riscv/configs/defconfig        |   2 +-
 arch/riscv/include/asm/pgalloc.h    |  32 ++++
 arch/riscv/include/asm/pgtable-64.h |  21 +++
 arch/riscv/include/asm/pgtable.h    |  53 +++++-
 arch/riscv/include/asm/sbi.h        |  10 +
 arch/riscv/kernel/head.S            |   7 +-
 arch/riscv/kernel/sbi.c             |  61 +++++++
 arch/riscv/kernel/setup.c           |  27 +++
 arch/riscv/mm/init.c                |   3 +
 include/asm-generic/pgalloc.h       | 142 +++++++++++++++
 include/linux/mmzone.h              |   2 +-
 include/linux/pgtable.h             |   8 +
 include/linux/pt_area.h             |  25 +++
 init/main.c                         |  85 +++++++++
 mm/Makefile                         |   4 +
 mm/memory.c                         |   1 +
 mm/pt_area.c                        | 273 ++++++++++++++++++++++++++++
 mm/swap_state.c                     |  17 +-
 19 files changed, 774 insertions(+), 7 deletions(-)
 create mode 100644 include/linux/pt_area.h
 create mode 100644 mm/pt_area.c

diff --git a/arch/riscv/Kconfig b/arch/riscv/Kconfig
index 44377fd78..218d19c26 100644
--- a/arch/riscv/Kconfig
+++ b/arch/riscv/Kconfig
@@ -111,6 +111,14 @@ config RISCV_SBI
 	depends on !RISCV_M_MODE
 	default y
 
+config PT_AREA
+  	bool 
+	default y
+
+config EARLY_PRINTK
+  	bool 
+	default y
+
 config MMU
 	bool "MMU-based Paged Memory Management Support"
 	default y
diff --git a/arch/riscv/configs/defconfig b/arch/riscv/configs/defconfig
index d222d353d..24f8b8095 100644
--- a/arch/riscv/configs/defconfig
+++ b/arch/riscv/configs/defconfig
@@ -118,7 +118,7 @@ CONFIG_DEBUG_RT_MUTEXES=y
 CONFIG_DEBUG_SPINLOCK=y
 CONFIG_DEBUG_MUTEXES=y
 CONFIG_DEBUG_RWSEMS=y
-CONFIG_DEBUG_ATOMIC_SLEEP=y
+CONFIG_DEBUG_ATOMIC_SLEEP=n
 CONFIG_STACKTRACE=y
 CONFIG_DEBUG_LIST=y
 CONFIG_DEBUG_PLIST=y
diff --git a/arch/riscv/include/asm/pgalloc.h b/arch/riscv/include/asm/pgalloc.h
index 23b1544e0..4653ad5e8 100644
--- a/arch/riscv/include/asm/pgalloc.h
+++ b/arch/riscv/include/asm/pgalloc.h
@@ -10,6 +10,11 @@
 #include <linux/mm.h>
 #include <asm/tlb.h>
 
+#ifdef CONFIG_PT_AREA
+#include <linux/pt_area.h>
+#include <asm/sbi.h>
+#endif
+
 #ifdef CONFIG_MMU
 #include <asm-generic/pgalloc.h>
 
@@ -39,7 +44,33 @@ static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)
 #endif /* __PAGETABLE_PMD_FOLDED */
 
 #define pmd_pgtable(pmd)	pmd_page(pmd)
+#ifdef CONFIG_PT_AREA
+static inline pgd_t *pgd_alloc(struct mm_struct *mm)
+{
+	pgd_t *pgd;
 
+	pgd = (pgd_t *)alloc_pt_pgd_page();
+	if(likely(pgd != NULL))
+	{
+		if(enclave_module_installed)
+		{
+		SBI_PENGLAI_ECALL_4(SBI_SM_SET_PTE, SBI_PTE_MEMSET, __pa(pgd), 0, USER_PTRS_PER_PGD * sizeof(pgd_t));
+		SBI_PENGLAI_ECALL_4(SBI_SM_SET_PTE, SBI_PTE_MEMCPY, __pa(pgd + USER_PTRS_PER_PGD),
+			__pa(init_mm.pgd + USER_PTRS_PER_PGD),
+			(PTRS_PER_PGD - USER_PTRS_PER_PGD) * sizeof(pgd_t));
+		}
+		else
+		{
+		memset(pgd, 0, USER_PTRS_PER_PGD * sizeof(pgd_t));
+		/* Copy kernel mappings */
+		memcpy(pgd + USER_PTRS_PER_PGD,
+			init_mm.pgd + USER_PTRS_PER_PGD,
+			(PTRS_PER_PGD - USER_PTRS_PER_PGD) * sizeof(pgd_t));
+		}
+	}
+	return pgd;
+}
+#else /* CONFIG_PT_AREA */
 static inline pgd_t *pgd_alloc(struct mm_struct *mm)
 {
 	pgd_t *pgd;
@@ -54,6 +85,7 @@ static inline pgd_t *pgd_alloc(struct mm_struct *mm)
 	}
 	return pgd;
 }
+#endif /* CONFIG_PT_AREA */
 
 #ifndef __PAGETABLE_PMD_FOLDED
 
diff --git a/arch/riscv/include/asm/pgtable-64.h b/arch/riscv/include/asm/pgtable-64.h
index f3b0da64c..e7129dd69 100644
--- a/arch/riscv/include/asm/pgtable-64.h
+++ b/arch/riscv/include/asm/pgtable-64.h
@@ -7,6 +7,7 @@
 #define _ASM_RISCV_PGTABLE_64_H
 
 #include <linux/const.h>
+#include <asm/sbi.h>
 
 #define PGDIR_SHIFT     30
 /* Size of region mapped by a page global directory */
@@ -50,10 +51,30 @@ static inline int pud_leaf(pud_t pud)
 	       (pud_val(pud) & (_PAGE_READ | _PAGE_WRITE | _PAGE_EXEC));
 }
 
+#ifdef CONFIG_PT_AREA
+extern int enclave_module_installed;
+#define SBI_SM_SET_PTE 101
+#define SBI_SET_PTE_ONE 1
+#define SBI_PTE_MEMSET 2
+#define SBI_PTE_MEMCPY 3
+
+static void set_pud(pud_t *pudp, pud_t pud)
+{
+  if(enclave_module_installed)
+  {
+    SBI_PENGLAI_ECALL_4(SBI_SM_SET_PTE, SBI_SET_PTE_ONE, __pa(pudp), pud.p4d.pgd.pgd, 0);
+  }
+  else
+  {
+    *pudp = pud;
+  }
+}
+#else
 static inline void set_pud(pud_t *pudp, pud_t pud)
 {
 	*pudp = pud;
 }
+#endif /*CONFIG_PT_AREA*/
 
 static inline void pud_clear(pud_t *pudp)
 {
diff --git a/arch/riscv/include/asm/pgtable.h b/arch/riscv/include/asm/pgtable.h
index 183f1f4b2..24b54961e 100644
--- a/arch/riscv/include/asm/pgtable.h
+++ b/arch/riscv/include/asm/pgtable.h
@@ -18,6 +18,7 @@
 #include <asm/page.h>
 #include <asm/tlbflush.h>
 #include <linux/mm_types.h>
+#include <asm/sbi.h>
 
 #ifdef CONFIG_MMU
 
@@ -114,6 +115,10 @@
 #define _PAGE_IOREMAP _PAGE_KERNEL
 
 extern pgd_t swapper_pg_dir[];
+//penglai extension
+#ifdef CONFIG_PT_AREA
+extern pgd_t *new_swapper_pg_dir;
+#endif /*CONFIG_PT_AREA*/
 
 /* MAP_PRIVATE permissions: xwr (copy-on-write) */
 #define __P000	PAGE_NONE
@@ -159,7 +164,16 @@ static inline int pmd_leaf(pmd_t pmd)
 
 static inline void set_pmd(pmd_t *pmdp, pmd_t pmd)
 {
+	#ifdef CONFIG_PT_AREA
+	if(enclave_module_installed)
+	{
+		SBI_PENGLAI_ECALL_4(SBI_SM_SET_PTE, SBI_SET_PTE_ONE, __pa(pmdp), pmd.pmd, 0);
+	}
+	else
+		*pmdp=pmd;
+	#else
 	*pmdp = pmd;
+	#endif /*CONFIG_PT_AREA*/
 }
 
 static inline void pmd_clear(pmd_t *pmdp)
@@ -327,7 +341,16 @@ static inline int pte_same(pte_t pte_a, pte_t pte_b)
  */
 static inline void set_pte(pte_t *ptep, pte_t pteval)
 {
-	*ptep = pteval;
+	#ifdef CONFIG_PT_AREA
+	if(enclave_module_installed)
+	{
+		SBI_PENGLAI_ECALL_4(SBI_SM_SET_PTE, SBI_SET_PTE_ONE, __pa(ptep), pteval.pte, 0);
+	}
+	else
+		*ptep = pteval;
+	#else
+		*ptep = pteval;
+	#endif /*CONFIG_PT_AREA*/
 }
 
 void flush_icache_pte(pte_t pte);
@@ -365,7 +388,18 @@ static inline int ptep_set_access_flags(struct vm_area_struct *vma,
 static inline pte_t ptep_get_and_clear(struct mm_struct *mm,
 				       unsigned long address, pte_t *ptep)
 {
-	return __pte(atomic_long_xchg((atomic_long_t *)ptep, 0));
+	#ifdef CONFIG_PT_AREA
+	if(enclave_module_installed)
+	{
+		pte_t pte = *ptep;
+		pte_clear(mm, address, ptep);
+		return pte;
+	}
+	else
+		return __pte(atomic_long_xchg((atomic_long_t *)ptep, 0));
+	#else
+		return __pte(atomic_long_xchg((atomic_long_t *)ptep, 0));
+	#endif
 }
 
 #define __HAVE_ARCH_PTEP_TEST_AND_CLEAR_YOUNG
@@ -382,7 +416,20 @@ static inline int ptep_test_and_clear_young(struct vm_area_struct *vma,
 static inline void ptep_set_wrprotect(struct mm_struct *mm,
 				      unsigned long address, pte_t *ptep)
 {
-	atomic_long_and(~(unsigned long)_PAGE_WRITE, (atomic_long_t *)ptep);
+	#ifdef CONFIG_PT_AREA
+	if(enclave_module_installed)
+	{
+		pte_t pteval;
+		pteval.pte = (~(unsigned long)_PAGE_WRITE) & (ptep->pte);
+		SBI_PENGLAI_ECALL_4(SBI_SM_SET_PTE, SBI_SET_PTE_ONE, __pa(ptep), pteval.pte, 0);
+	}
+	else
+	{
+		atomic_long_and(~(unsigned long)_PAGE_WRITE, (atomic_long_t *)ptep);
+	}
+	#else
+		atomic_long_and(~(unsigned long)_PAGE_WRITE, (atomic_long_t *)ptep);
+	#endif
 }
 
 #define __HAVE_ARCH_PTEP_CLEAR_YOUNG_FLUSH
diff --git a/arch/riscv/include/asm/sbi.h b/arch/riscv/include/asm/sbi.h
index 653edb25d..56ac0c7db 100644
--- a/arch/riscv/include/asm/sbi.h
+++ b/arch/riscv/include/asm/sbi.h
@@ -27,6 +27,9 @@ enum sbi_ext_id {
 	SBI_EXT_IPI = 0x735049,
 	SBI_EXT_RFENCE = 0x52464E43,
 	SBI_EXT_HSM = 0x48534D,
+	//TODO:
+	//Why this magic number
+	SBI_EXT_PENGLAI = 0x100100,
 };
 
 enum sbi_ext_base_fid {
@@ -95,6 +98,13 @@ struct sbiret sbi_ecall(int ext, int fid, unsigned long arg0,
 			unsigned long arg3, unsigned long arg4,
 			unsigned long arg5);
 
+long SBI_PENGLAI_ECALL_0(int fid);
+long SBI_PENGLAI_ECALL_1(int fid, unsigned long arg0);
+long SBI_PENGLAI_ECALL_2(int fid, unsigned long arg0, unsigned long arg1);
+long SBI_PENGLAI_ECALL_3(int fid, unsigned long arg0, unsigned long arg1, unsigned long arg2);
+long SBI_PENGLAI_ECALL_4(int fid, unsigned long arg0, unsigned long arg1, unsigned long arg2, unsigned long arg3);
+long SBI_PENGLAI_ECALL_5(int fid, unsigned long arg0, unsigned long arg1, unsigned long arg2, unsigned long arg3, unsigned long arg4);
+
 void sbi_console_putchar(int ch);
 int sbi_console_getchar(void);
 void sbi_set_timer(uint64_t stime_value);
diff --git a/arch/riscv/kernel/head.S b/arch/riscv/kernel/head.S
index 7e849797c..dab0f3c3a 100644
--- a/arch/riscv/kernel/head.S
+++ b/arch/riscv/kernel/head.S
@@ -155,7 +155,12 @@ secondary_start_common:
 
 #ifdef CONFIG_MMU
 	/* Enable virtual memory and relocate to virtual address */
-	la a0, swapper_pg_dir
+	#ifdef CONFIG_PT_AREA
+		la a0, new_swapper_pg_dir
+		ld a0, (a0)
+	#else
+		la a0, swapper_pg_dir
+	#endif
 	call relocate
 #endif
 	call setup_trap_vector
diff --git a/arch/riscv/kernel/sbi.c b/arch/riscv/kernel/sbi.c
index 226ccce0f..98ce3c655 100644
--- a/arch/riscv/kernel/sbi.c
+++ b/arch/riscv/kernel/sbi.c
@@ -46,6 +46,67 @@ struct sbiret sbi_ecall(int ext, int fid, unsigned long arg0,
 }
 EXPORT_SYMBOL(sbi_ecall);
 
+long SBI_PENGLAI_ECALL_0(int fid)
+{
+	struct sbiret ret;
+	ret = sbi_ecall(SBI_EXT_PENGLAI, fid, 0, 0, 0, 0, 0, 0);
+	if (ret.error == 0)
+		return ret.value;
+	return ret.error;
+}
+
+long SBI_PENGLAI_ECALL_1(int fid, unsigned long arg0)
+{
+	struct sbiret ret;
+	ret = sbi_ecall(SBI_EXT_PENGLAI, fid, arg0, 0, 0, 0, 0, 0);
+	if (ret.error == 0)
+		return ret.value;
+	return ret.error;
+}
+
+long SBI_PENGLAI_ECALL_2(int fid, unsigned long arg0, unsigned long arg1)
+{
+	struct sbiret ret;
+	ret = sbi_ecall(SBI_EXT_PENGLAI, fid, arg0, arg1, 0, 0, 0, 0);
+	if (ret.error == 0)
+		return ret.value;
+	return ret.error;
+}
+
+long SBI_PENGLAI_ECALL_3(int fid, unsigned long arg0, unsigned long arg1, unsigned long arg2)
+{
+	struct sbiret ret;
+	ret = sbi_ecall(SBI_EXT_PENGLAI, fid, arg0, arg1, arg2, 0, 0, 0);
+	if (ret.error == 0)
+		return ret.value;
+	return ret.error;
+}
+
+long SBI_PENGLAI_ECALL_4(int fid, unsigned long arg0, unsigned long arg1, unsigned long arg2, unsigned long arg3)
+{
+	struct sbiret ret;
+	ret = sbi_ecall(SBI_EXT_PENGLAI, fid, arg0, arg1, arg2, arg3, 0, 0);
+	if (ret.error == 0)
+		return ret.value;
+	return ret.error;
+}
+
+long SBI_PENGLAI_ECALL_5(int fid, unsigned long arg0, unsigned long arg1, unsigned long arg2, unsigned long arg3, unsigned long arg4)
+{
+	struct sbiret ret;
+	ret = sbi_ecall(SBI_EXT_PENGLAI, fid, arg0, arg1, arg2, arg3, arg4, 0);
+	if (ret.error == 0)
+		return ret.value;
+	return ret.error;
+}
+
+EXPORT_SYMBOL(SBI_PENGLAI_ECALL_0);
+EXPORT_SYMBOL(SBI_PENGLAI_ECALL_1);
+EXPORT_SYMBOL(SBI_PENGLAI_ECALL_2);
+EXPORT_SYMBOL(SBI_PENGLAI_ECALL_3);
+EXPORT_SYMBOL(SBI_PENGLAI_ECALL_4);
+EXPORT_SYMBOL(SBI_PENGLAI_ECALL_5);
+
 int sbi_err_map_linux_errno(int err)
 {
 	switch (err) {
diff --git a/arch/riscv/kernel/setup.c b/arch/riscv/kernel/setup.c
index 117f3212a..0103d2649 100644
--- a/arch/riscv/kernel/setup.c
+++ b/arch/riscv/kernel/setup.c
@@ -64,8 +64,35 @@ static void __init parse_dtb(void)
 #endif
 }
 
+#ifdef CONFIG_EARLY_PRINTK
+static void sbi_console_write(struct console *co, const char *buf,
+			      unsigned int n)
+{
+	int i;
+
+	for (i = 0; i < n; ++i) {
+		if (buf[i] == '\n')
+			sbi_console_putchar('\r');
+		sbi_console_putchar(buf[i]);
+	}
+}
+
+struct console riscv_sbi_early_console_dev __initdata = {
+	.name	= "early",
+	.write	= sbi_console_write,
+	.flags	= CON_PRINTBUFFER | CON_BOOT | CON_ANYTIME,
+	.index	= -1
+};
+#endif
+
 void __init setup_arch(char **cmdline_p)
 {
+#if defined(CONFIG_EARLY_PRINTK)
+       if (likely(early_console == NULL)) {
+               early_console = &riscv_sbi_early_console_dev;
+               register_console(early_console);
+       }
+#endif
 	parse_dtb();
 	init_mm.start_code = (unsigned long) _stext;
 	init_mm.end_code   = (unsigned long) _etext;
diff --git a/arch/riscv/mm/init.c b/arch/riscv/mm/init.c
index 8e577f14f..f05c8940b 100644
--- a/arch/riscv/mm/init.c
+++ b/arch/riscv/mm/init.c
@@ -208,6 +208,9 @@ EXPORT_SYMBOL(pfn_base);
 
 pgd_t swapper_pg_dir[PTRS_PER_PGD] __page_aligned_bss;
 pgd_t trampoline_pg_dir[PTRS_PER_PGD] __page_aligned_bss;
+#ifdef CONFIG_PT_AREA
+pgd_t *new_swapper_pg_dir;
+#endif
 pte_t fixmap_pte[PTRS_PER_PTE] __page_aligned_bss;
 
 #define MAX_EARLY_MAPPING_SIZE	SZ_128M
diff --git a/include/asm-generic/pgalloc.h b/include/asm-generic/pgalloc.h
index 02932efad..1bba4f1a5 100644
--- a/include/asm-generic/pgalloc.h
+++ b/include/asm-generic/pgalloc.h
@@ -2,11 +2,151 @@
 #ifndef __ASM_GENERIC_PGALLOC_H
 #define __ASM_GENERIC_PGALLOC_H
 
+#ifdef CONFIG_PT_AREA
+#include <linux/pt_area.h>
+#include <asm/atomic.h>
+#endif
+
 #ifdef CONFIG_MMU
 
 #define GFP_PGTABLE_KERNEL	(GFP_KERNEL | __GFP_ZERO)
 #define GFP_PGTABLE_USER	(GFP_PGTABLE_KERNEL | __GFP_ACCOUNT)
 
+#ifdef CONFIG_PT_AREA
+
+static inline pte_t *__pte_alloc_one_kernel(struct mm_struct *mm)
+{
+	pte_t* pte;
+	pte = (pte_t*) alloc_pt_pte_page();
+	return pte;
+}
+
+#ifndef __HAVE_ARCH_PTE_ALLOC_ONE_KERNEL
+static inline pte_t *pte_alloc_one_kernel(struct mm_struct *mm)
+{
+	return __pte_alloc_one_kernel(mm);
+}
+#endif
+
+
+
+
+static inline void pte_free_kernel(struct mm_struct *mm, pte_t *pte)
+{
+	free_pt_pte_page((unsigned long)pte);
+}
+
+static inline pgtable_t __pte_alloc_one(struct mm_struct *mm, gfp_t gfp)
+{
+	struct page *pte;
+
+	pte = virt_to_page((void*)(alloc_pt_pte_page()));
+	if (!pte)
+		return NULL;
+	if (!pgtable_pte_page_ctor(pte)) {
+		free_pt_pte_page((unsigned long)(page_address(pte)));
+		return NULL;
+	}
+	return pte;
+}
+
+#ifndef __HAVE_ARCH_PTE_ALLOC_ONE
+static inline pgtable_t pte_alloc_one(struct mm_struct *mm)
+{
+	return __pte_alloc_one(mm, GFP_PGTABLE_USER);
+}
+#endif
+
+static inline void pte_free(struct mm_struct *mm, struct page *pte_page)
+{
+	pgtable_pte_page_dtor(pte_page);
+	*(unsigned long *)&pte_page->ptl = 0;
+	free_pt_pte_page((unsigned long)(page_address(pte_page)));
+}
+
+static inline void pte_free_no_dtor(struct mm_struct *mm, struct page *pte_page)
+{
+	*(unsigned long *)&pte_page->ptl = 0;
+	free_pt_pte_page((unsigned long)(page_address(pte_page)));
+}
+
+static inline int check_pte(struct mm_struct *mm, struct page *pte_page)
+{
+	return check_pt_pte_page((unsigned long)(page_address(pte_page)));
+}
+
+#if CONFIG_PGTABLE_LEVELS > 2
+
+#ifndef __HAVE_ARCH_PMD_ALLOC_ONE
+static inline pmd_t *pmd_alloc_one(struct mm_struct *mm, unsigned long addr)
+{
+	struct page *page;
+	gfp_t gfp = GFP_PGTABLE_USER;
+
+	if (mm == &init_mm)
+		gfp = GFP_PGTABLE_KERNEL;
+	page = virt_to_page((void *)alloc_pt_pmd_page());
+	if (!page)
+		return NULL;
+	if (!pgtable_pmd_page_ctor(page)) {
+		free_pt_pmd_page((unsigned long)(page_address(page)));
+		return NULL;
+	}
+	return (pmd_t *)page_address(page);
+}
+#endif
+
+#ifndef __HAVE_ARCH_PMD_FREE
+static inline void pmd_free(struct mm_struct *mm, pmd_t *pmd)
+{
+	struct page *page = virt_to_page(pmd);
+	pgtable_pmd_page_dtor(page);
+	*(unsigned long *)&page->ptl = 0;
+	free_pt_pmd_page((unsigned long)pmd);
+}
+#endif
+
+#ifndef __HAVE_ARCH_PMD_FREE
+static inline void pmd_free_no_dtor(struct mm_struct *mm, pmd_t *pmd)
+{
+	free_pt_pmd_page((unsigned long)pmd);
+}
+#endif
+
+#endif /* CONFIG_PGTABLE_LEVELS > 2 */
+
+#if CONFIG_PGTABLE_LEVELS > 3
+
+#ifndef __HAVE_ARCH_PUD_ALLOC_ONE
+static inline pud_t *pud_alloc_one(struct mm_struct *mm, unsigned long addr)
+{
+	gfp_t gfp = GFP_PGTABLE_USER;
+
+	if (mm == &init_mm)
+		gfp = GFP_PGTABLE_KERNEL;
+	return (pud_t *)get_zeroed_page(gfp);
+}
+#endif
+
+static inline void pud_free(struct mm_struct *mm, pud_t *pud)
+{
+	BUG_ON((unsigned long)pud & (PAGE_SIZE-1));
+	free_page((unsigned long)pud);
+}
+
+#endif /* CONFIG_PGTABLE_LEVELS > 3 */
+
+#ifndef __HAVE_ARCH_PGD_FREE
+static inline void pgd_free(struct mm_struct *mm, pgd_t *pgd)
+{
+	free_pt_pgd_page((unsigned long)pgd);
+}
+#endif
+
+
+
+#else
+
 /**
  * __pte_alloc_one_kernel - allocate a page for PTE-level kernel page table
  * @mm: the mm_struct of the current context
@@ -182,6 +322,8 @@ static inline void pgd_free(struct mm_struct *mm, pgd_t *pgd)
 }
 #endif
 
+#endif /* CONFIG_PT_AREA */
+
 #endif /* CONFIG_MMU */
 
 #endif /* __ASM_GENERIC_PGALLOC_H */
diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h
index fb3bf696c..6e2a1f8d7 100644
--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@ -24,7 +24,7 @@
 
 /* Free memory management - zoned buddy allocator.  */
 #ifndef CONFIG_FORCE_MAX_ZONEORDER
-#define MAX_ORDER 11
+#define MAX_ORDER 18
 #else
 #define MAX_ORDER CONFIG_FORCE_MAX_ZONEORDER
 #endif
diff --git a/include/linux/pgtable.h b/include/linux/pgtable.h
index e237004d4..960998bd4 100644
--- a/include/linux/pgtable.h
+++ b/include/linux/pgtable.h
@@ -93,6 +93,14 @@ static inline pmd_t *pmd_offset(pud_t *pud, unsigned long address)
 #define pmd_offset pmd_offset
 #endif
 
+#ifndef pte_offset
+static inline pte_t *pte_offset(pmd_t *pmd, unsigned long address)
+{
+	return (pte_t *)pmd_page_vaddr(*pmd) + pte_index(address);
+}
+#define pte_offset pte_offset
+#endif
+
 #ifndef pud_offset
 static inline pud_t *pud_offset(p4d_t *p4d, unsigned long address)
 {
diff --git a/include/linux/pt_area.h b/include/linux/pt_area.h
new file mode 100644
index 000000000..ef301313e
--- /dev/null
+++ b/include/linux/pt_area.h
@@ -0,0 +1,25 @@
+#ifndef _LINUX_PT_AREA_H
+#define _LINUX_PT_AREA_H
+#define DEFAULT_PGD_PAGE_ORDER 8
+#define DEFAULT_PMD_PAGE_ORDER 10
+
+void init_pt_area(void);
+
+unsigned long pt_pages_num(void);
+
+unsigned long pt_free_pages_num(void);
+
+char* alloc_pt_pgd_page(void);
+
+char* alloc_pt_pmd_page(void);
+
+char* alloc_pt_pte_page(void);
+
+int free_pt_pgd_page(unsigned long page);
+
+int free_pt_pmd_page(unsigned long page);
+
+int free_pt_pte_page(unsigned long page);
+
+int check_pt_pte_page(unsigned long page);
+#endif /* _LINUX_PT_AREA_H */
diff --git a/init/main.c b/init/main.c
index 32b2a8aff..3742d68db 100644
--- a/init/main.c
+++ b/init/main.c
@@ -105,6 +105,13 @@
 #include <asm/sections.h>
 #include <asm/cacheflush.h>
 
+#ifdef CONFIG_PT_AREA
+#include <linux/pt_area.h>
+#include <asm/tlbflush.h>
+#include <asm/page.h>
+#endif
+
+
 #define CREATE_TRACE_POINTS
 #include <trace/events/initcall.h>
 
@@ -840,6 +847,80 @@ static void __init mm_init(void)
 	pti_init();
 }
 
+#ifdef CONFIG_PT_AREA
+static void deep_copy_pt(pte_t* src_pt, pte_t* dest_pt, int level)
+{
+  unsigned long i=0;
+  int tmpLevel = level;
+  for(i=0;i<PTRS_PER_PGD;++i)
+  {
+    unsigned long pte=src_pt[i].pte;
+    if(pte & _PAGE_PRESENT)
+    {
+      if((pte & _PAGE_READ) || (pte & _PAGE_EXEC))
+      {
+        //Find a leaf PTE
+        dest_pt[i]=__pte(pte);
+      }
+      else
+      {
+        pte_t* new_dest_pt;
+        pte_t* new_src_pt;
+		if (tmpLevel == 0){
+			new_dest_pt=(pte_t*)alloc_pt_pmd_page();
+		}
+		else{
+			new_dest_pt=(pte_t*)alloc_pt_pte_page();
+		}
+		new_src_pt=(pte_t*)pfn_to_virt(pte>>_PAGE_PFN_SHIFT);
+        deep_copy_pt(new_src_pt, new_dest_pt,level+1);
+        src_pt[i]=pfn_pte(PFN_DOWN(__pa(new_dest_pt)), __pgprot(pte & 0x3FF));
+        dest_pt[i]=pfn_pte(PFN_DOWN(__pa(new_dest_pt)), __pgprot(pte & 0x3FF));
+      }
+    }
+  }
+}
+
+/*
+ * Transfer the swapper pg dir that kernel uses during boot to pt area
+ * This function can only be called after init_pt_area is called
+ */
+int enclave_module_installed = 0;
+extern unsigned long pt_area_vaddr;
+extern unsigned long pt_area_pages;
+static void transfer_init_pt(void)
+{
+  pte_t* new_swapper_pt;
+  unsigned long i=0;
+  pr_notice("Transfer init table\n");
+#ifndef __PAGETABLE_PMD_FOLDED
+  BUG_ON((PTRS_PER_PGD != PTRS_PER_PTE) || (PTRS_PER_PTE != PTRS_PER_PMD));
+#else
+  BUG_ON(PTRS_PER_PGD != PTRS_PER_PTE);
+#endif
+
+  //Actually here should be pgd_t or pmd_t or pte_t, just for simplicity
+  new_swapper_pt=(pte_t*)alloc_pt_pgd_page();
+  new_swapper_pg_dir=(void*)__pa(new_swapper_pt);
+  deep_copy_pt((pte_t*)swapper_pg_dir, new_swapper_pt,0);
+  mb();
+
+  pr_notice("Before transfer init table: sptbr is 0x%lx, init_mm.pgd is 0x%lx\n",csr_read(sptbr),(unsigned long)init_mm.pgd);
+  init_mm.pgd=(pgd_t*)new_swapper_pt;
+  csr_write(sptbr, virt_to_pfn(new_swapper_pt) | SATP_MODE);
+  local_flush_tlb_all();
+  pr_notice("After transfer init table: sptbr is 0x%lx, init_mm.pgd is 0x%lx\n",csr_read(sptbr),(unsigned long)init_mm.pgd);
+  
+  //clear swapper_pg_dir
+  for(i=0;i<PTRS_PER_PGD;++i)
+  {
+    swapper_pg_dir[i].pgd=0;
+  }
+  enclave_module_installed = 1;
+}
+
+#endif /* CONFIG_PT_AREA */
+
 void __init __weak arch_call_rest_init(void)
 {
 	rest_init();
@@ -903,6 +984,10 @@ asmlinkage __visible void __init __no_sanitize_address start_kernel(void)
 	trap_init();
 	mm_init();
 
+	#ifdef CONFIG_PT_AREA
+	init_pt_area();
+	transfer_init_pt();
+	#endif
 	ftrace_init();
 
 	/* trace_printk can be enabled here */
diff --git a/mm/Makefile b/mm/Makefile
index d73aed0fc..6e3251c99 100644
--- a/mm/Makefile
+++ b/mm/Makefile
@@ -66,6 +66,10 @@ ifdef CONFIG_MMU
 	obj-$(CONFIG_ADVISE_SYSCALLS)	+= madvise.o
 endif
 
+ifdef CONFIG_PT_AREA
+	obj-y   += pt_area.o
+endif
+
 obj-$(CONFIG_SWAP)	+= page_io.o swap_state.o swapfile.o swap_slots.o
 obj-$(CONFIG_FRONTSWAP)	+= frontswap.o
 obj-$(CONFIG_ZSWAP)	+= zswap.o
diff --git a/mm/memory.c b/mm/memory.c
index c48f8df6e..1b2f59512 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -216,6 +216,7 @@ static void free_pte_range(struct mmu_gather *tlb, pmd_t *pmd,
 			   unsigned long addr)
 {
 	pgtable_t token = pmd_pgtable(*pmd);
+
 	pmd_clear(pmd);
 	pte_free_tlb(tlb, token, addr);
 	mm_dec_nr_ptes(tlb->mm);
diff --git a/mm/pt_area.c b/mm/pt_area.c
new file mode 100644
index 000000000..6bb0ae982
--- /dev/null
+++ b/mm/pt_area.c
@@ -0,0 +1,273 @@
+#include <asm/page.h>
+#include <asm/pgtable.h>
+#include <linux/gfp.h>
+#include <linux/pt_area.h>
+
+int PGD_PAGE_ORDER=DEFAULT_PGD_PAGE_ORDER;
+int PMD_PAGE_ORDER=DEFAULT_PMD_PAGE_ORDER;
+int PTE_PAGE_NUM;
+
+char *pt_area_vaddr;
+unsigned long pt_area_pages;
+unsigned long pt_free_pages;
+EXPORT_SYMBOL(pt_area_vaddr);
+EXPORT_SYMBOL(pt_area_pages);
+EXPORT_SYMBOL(pt_free_pages);
+EXPORT_SYMBOL(PGD_PAGE_ORDER);
+EXPORT_SYMBOL(PMD_PAGE_ORDER);
+EXPORT_SYMBOL(alloc_pt_pte_page);
+
+extern unsigned long _totalram_pages;
+
+struct pt_page_list{
+  struct pt_page_list *next_page;
+};
+
+struct pt_page_list *pt_pgd_page_list = NULL;
+struct pt_page_list *pt_pgd_free_list = NULL;
+struct pt_page_list *pt_pmd_page_list = NULL;
+struct pt_page_list *pt_pmd_free_list = NULL;
+struct pt_page_list *pt_pte_page_list = NULL;
+struct pt_page_list *pt_pte_free_list = NULL;
+EXPORT_SYMBOL(pt_pte_page_list);
+EXPORT_SYMBOL(pt_pte_free_list);
+
+spinlock_t pt_lock;
+EXPORT_SYMBOL(pt_lock);
+
+/* This function allocates a contionuous piece of memory for pt area.
+ * PT area is used for storing page tables.
+ * This function can only be called after mm_init() is called
+ */
+void init_pt_area()
+{
+  //page: computing the number of the page table page 
+  unsigned long pages = (_totalram_pages % PTRS_PER_PTE) ? (_totalram_pages/PTRS_PER_PTE + 1) : (_totalram_pages/PTRS_PER_PTE);
+  unsigned long order = ilog2(pages - 1) + 4;
+
+  unsigned long i = 0;
+  pt_area_pages = 1 << order;
+  PTE_PAGE_NUM = pt_area_pages - (1<<PGD_PAGE_ORDER) - (1<<PMD_PAGE_ORDER);
+  pt_free_pages=pt_area_pages;
+  pt_area_vaddr = (void*)__get_free_pages(GFP_KERNEL, order);
+  if(pt_area_vaddr == NULL)
+  {
+    panic("ERROR: init_pt_area: alloc pages for pt area failed!\n");
+    while(1){}
+  }
+
+  //pages: computing the size of te page metadata space
+  pages = pt_area_pages * sizeof(struct pt_page_list);
+  pages = (pages % PAGE_SIZE) == 0 ? (pages / PAGE_SIZE) : (pages / PAGE_SIZE + 1);
+  order = ilog2(pages - 1) + 1;
+
+  pt_pgd_page_list = (struct pt_page_list* )__get_free_pages(GFP_KERNEL, order);
+  pt_pmd_page_list = (struct pt_page_list* )__get_free_pages(GFP_KERNEL, order);
+  pt_pte_page_list = (struct pt_page_list* )__get_free_pages(GFP_KERNEL, order);
+  if((pt_pgd_page_list == NULL) || (pt_pmd_page_list == NULL) || (pt_pte_page_list == NULL))
+  {
+    panic("ERROR: init_pt_area: alloc pages for pt_pgd_pmd_pte_page_list failed!\n");
+    while(1){}
+  }
+  spin_lock_init(&pt_lock);
+  spin_lock(&pt_lock);
+  for (i = 0; i < (1<<PGD_PAGE_ORDER);++i)
+  {
+    pt_pgd_page_list[i].next_page = pt_pgd_free_list;
+    pt_pgd_free_list = &pt_pgd_page_list[i];
+  }
+  i = 0;
+  for (i = 0; i < (1<<PMD_PAGE_ORDER);++i)
+  {
+    pt_pmd_page_list[i].next_page = pt_pmd_free_list;
+    pt_pmd_free_list = &pt_pmd_page_list[i];
+  }
+  i = 0;
+  for (i = 0; i < PTE_PAGE_NUM;++i)
+  {
+    pt_pte_page_list[i].next_page = pt_pte_free_list;
+    pt_pte_free_list = &pt_pte_page_list[i];
+  }
+  printk("Init_pt_area: 0x%lx/0x%lx pt pages available!\n",pt_free_pages,pt_area_pages);
+  spin_unlock(&pt_lock);
+}
+
+unsigned long pt_pages_num()
+{
+  return pt_area_pages;
+}
+
+unsigned long pt_free_pages_num()
+{
+  return pt_free_pages;
+}
+
+char* alloc_pt_pgd_page()
+{
+  unsigned long pt_page_num;
+  char* free_page;
+  spin_lock(&pt_lock);
+
+  if(pt_pgd_free_list == NULL){
+    panic("PANIC: there is no free page in PT area for pgd!\n");
+    while(1){}
+  }
+
+  pt_page_num = (pt_pgd_free_list - pt_pgd_page_list);
+  //need free_page offset
+  free_page = pt_area_vaddr + pt_page_num * PAGE_SIZE;
+  pt_pgd_free_list = pt_pgd_free_list->next_page;
+  pt_free_pages -= 1;
+
+  spin_unlock(&pt_lock);
+  if(enclave_module_installed)
+  {
+    SBI_PENGLAI_ECALL_4(SBI_SM_SET_PTE, SBI_PTE_MEMSET, __pa(free_page), 0, PAGE_SIZE);
+  }
+  else
+  {
+    memset(free_page, 0, PAGE_SIZE);
+  }
+  return free_page;
+}
+
+char* alloc_pt_pmd_page()
+{
+  unsigned long pt_page_num;
+  char* free_page;
+  spin_lock(&pt_lock);
+  if(pt_pmd_free_list == NULL){
+    panic("PANIC: there is no free page in PT area for pmd!\n");
+    while(1){}
+  }
+  pt_page_num = (pt_pmd_free_list - pt_pmd_page_list);
+  //need free_page offset
+  free_page = pt_area_vaddr + (pt_page_num + (1<<PGD_PAGE_ORDER))* PAGE_SIZE;
+  pt_pmd_free_list = pt_pmd_free_list->next_page;
+  pt_free_pages -= 1;
+  spin_unlock(&pt_lock);
+  if(enclave_module_installed)
+  {
+    SBI_PENGLAI_ECALL_4(SBI_SM_SET_PTE, SBI_PTE_MEMSET, __pa(free_page), 0, PAGE_SIZE);
+  }
+  else
+  {
+    memset(free_page, 0, PAGE_SIZE);
+  }
+  return free_page;
+}
+
+char* alloc_pt_pte_page()
+{
+  unsigned long pt_page_num;
+  char* free_page;
+  spin_lock(&pt_lock);
+
+  if(pt_pte_free_list == NULL){
+    panic("PANIC: there is no free page in PT area for pte!\n");
+    while(1){}
+  }
+  pt_page_num = (pt_pte_free_list - pt_pte_page_list);
+  //need free_page offset
+  free_page = pt_area_vaddr + (pt_page_num + (1<<PGD_PAGE_ORDER) + (1<<PMD_PAGE_ORDER))* PAGE_SIZE;
+  pt_pte_free_list = pt_pte_free_list->next_page;
+  pt_free_pages -= 1;
+  spin_unlock(&pt_lock);
+  if(enclave_module_installed)
+  {
+    SBI_PENGLAI_ECALL_4(SBI_SM_SET_PTE, SBI_PTE_MEMSET, __pa(free_page), 0, PAGE_SIZE);
+  }
+  else
+  {
+    memset(free_page, 0, PAGE_SIZE);
+  }
+  return free_page;
+}
+
+int free_pt_pgd_page(unsigned long page)
+{
+  unsigned long pt_page_num;
+
+  if(((unsigned long)page % PAGE_SIZE)!=0){
+    panic("ERROR: free_pt_pgd_page: page is not PAGE_SIZE aligned!\n");
+    return -1; 
+  }
+  pt_page_num = ((char*)page - pt_area_vaddr) / PAGE_SIZE;
+  if(pt_page_num >= (1<<PGD_PAGE_ORDER))
+  {
+    panic("ERROR: free_pt_pgd_page: page is not in pt_area!\n");
+    return -1;
+  }
+
+  spin_lock(&pt_lock);
+
+  pt_pgd_page_list[pt_page_num].next_page = pt_pgd_free_list;
+  pt_pgd_free_list = &pt_pgd_page_list[pt_page_num];
+  pt_free_pages += 1;
+
+  spin_unlock(&pt_lock);
+
+  return  0;
+}
+
+int free_pt_pmd_page(unsigned long page)
+{
+  unsigned long pt_page_num;
+
+  if(((unsigned long)page % PAGE_SIZE)!=0){
+    panic("ERROR: free_pt_pmd_page: page is not PAGE_SIZE aligned!\n");
+    return -1; 
+  }
+  pt_page_num = (((char*)page - pt_area_vaddr) / PAGE_SIZE) - (1<<PGD_PAGE_ORDER);
+  if(pt_page_num >= (1<<PMD_PAGE_ORDER))
+  {
+    panic("ERROR: free_pt_pmd_page: page is not in pt_area!\n");
+    return -1;
+  }
+
+  spin_lock(&pt_lock);
+
+  pt_pmd_page_list[pt_page_num].next_page = pt_pmd_free_list;
+  pt_pmd_free_list = &pt_pmd_page_list[pt_page_num];
+  pt_free_pages += 1;
+
+  spin_unlock(&pt_lock);
+
+  return  0;
+}
+
+int free_pt_pte_page(unsigned long page)
+{
+  unsigned long pt_page_num;
+  if(((unsigned long)page % PAGE_SIZE)!=0){
+    panic("ERROR: free_pt_pte_page: page is not PAGE_SIZE aligned!\n");
+    return -1; 
+  }
+  pt_page_num = (((char*)page - pt_area_vaddr) / PAGE_SIZE) - (1<<PGD_PAGE_ORDER) - (1<<PMD_PAGE_ORDER);
+  if(pt_page_num >= (pt_area_pages - (1<<PGD_PAGE_ORDER) - (1<<PMD_PAGE_ORDER)))
+  {
+    panic("ERROR: free_pt_pte_page: page is not in pt_area! %lx\n", page);
+    return -1;
+  }
+
+  spin_lock(&pt_lock);
+
+  pt_pte_page_list[pt_page_num].next_page = pt_pte_free_list;
+  pt_pte_free_list = &pt_pte_page_list[pt_page_num];
+  pt_free_pages += 1;
+
+  spin_unlock(&pt_lock);
+
+  return  0;
+}
+
+int check_pt_pte_page(unsigned long page)
+{
+  unsigned long pt_page_num;
+  pt_page_num = (((char*)page - pt_area_vaddr) / PAGE_SIZE) - (1<<PGD_PAGE_ORDER) - (1<<PMD_PAGE_ORDER);
+  if(pt_page_num >= (pt_area_pages - (1<<PGD_PAGE_ORDER) - (1<<PMD_PAGE_ORDER)))
+  {
+    return -1;
+  }
+  return  0;
+}
diff --git a/mm/swap_state.c b/mm/swap_state.c
index ee4658274..464e4db89 100644
--- a/mm/swap_state.c
+++ b/mm/swap_state.c
@@ -24,6 +24,10 @@
 #include <linux/shmem_fs.h>
 #include "internal.h"
 
+#ifdef CONFIG_PT_AREA
+#include <asm/pgalloc.h>
+#endif
+
 /*
  * swapper_space is a fiction, retained to simplify the path through
  * vmscan's shrink_page_list.
@@ -352,7 +356,18 @@ void free_pages_and_swap_cache(struct page **pages, int nr)
 	lru_add_drain();
 	for (i = 0; i < nr; i++)
 		free_swap_cache(pagep[i]);
-	release_pages(pagep, nr);
+	#ifdef CONFIG_PT_AREA
+		// Remove the release_page, explicitly free the pte page in the free_pte_range()
+		for (i = 0; i < nr; i++)
+		{
+			if (check_pte(NULL, pagep[i]) == -1)
+				release_pages(pagep+i, 1);
+			else
+				pte_free_no_dtor(NULL, pagep[i]);
+		}
+	#else
+		release_pages(pagep, nr);
+	#endif
 }
 
 static inline bool swap_use_vma_readahead(void)
-- 
2.17.1

